{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## åŸºäºyolov5çš„æ•°ç‹¬æ£€æµ‹\n",
        "### 0.ç¯å¢ƒå®‰è£…"
      ],
      "metadata": {
        "collapsed": false,
        "id": "rSiWMcPFMopn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sudoku'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 28 (delta 7), reused 21 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (28/28), 25.15 MiB | 11.69 MiB/s, done.\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15598, done.\u001b[K\n",
            "remote: Counting objects: 100% (205/205), done.\u001b[K\n",
            "remote: Compressing objects: 100% (151/151), done.\u001b[K\n",
            "remote: Total 15598 (delta 98), reused 115 (delta 54), pack-reused 15393\u001b[K\n",
            "Receiving objects: 100% (15598/15598), 14.64 MiB | 28.55 MiB/s, done.\n",
            "Resolving deltas: 100% (10626/10626), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pk5ls20/sudoku.git\n",
        "!mv sudoku/* .\n",
        "%pip install -qr requirements.txt\n",
        "!git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "id": "YVSI364EMopp",
        "outputId": "e3e184b4-229d-403c-83b1-f161d1a5d0a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.æå–æ•°ç‹¬"
      ],
      "metadata": {
        "collapsed": false,
        "id": "6hb90fvEMopq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /root/.cache/torch/hub/requirements.txt not found, check failed.\n",
            "æ­£åœ¨å¤„ç†1.png...æå–æˆåŠŸï¼\n",
            "Done on 2023-04-27 03:29:15.493029\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import datetime\n",
        "import cv2\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='detect_sudoku.pt')\n",
        "input_path = 'sudoku_pic'\n",
        "output_path = 'sudoku_pic/extract'\n",
        "timex = lambda :datetime.datetime.now()\n",
        "for file_name in os.listdir(input_path):\n",
        "    if file_name.endswith('.jpg') or file_name.endswith('.png'):\n",
        "        print(f\"æ­£åœ¨å¤„ç†{file_name}\", end='')\n",
        "        img = cv2.imread(os.path.join(input_path, file_name))\n",
        "        # ä½¿ç”¨YOLOv5æ£€æµ‹\n",
        "        results = model(img)\n",
        "        # å¾—åˆ°ç½®ä¿¡åº¦æœ€é«˜çš„æ•°ç‹¬æ£€æµ‹ç»“æœ\n",
        "        sudoku_detection = None\n",
        "        for result in results.pred[0]:\n",
        "            if result[-1] == 0 and result[-2] > 0.8:\n",
        "                sudoku_detection = result\n",
        "                break\n",
        "        # æå–æ•°ç‹¬\n",
        "        if sudoku_detection is not None:\n",
        "            xmin, ymin, xmax, ymax, confidence = sudoku_detection[:5]\n",
        "            sudoku = img[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
        "            cv2.imwrite(os.path.join(output_path, f\"extract_{file_name}\"), sudoku)\n",
        "            print(f\"...æå–æˆåŠŸï¼\")\n",
        "        else:\n",
        "            print(f\"...{file_name}æœªæ£€æµ‹åˆ°æ•°ç‹¬ï¼\")\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "LKDd4Zs0Mopq",
        "outputId": "47efa7ff-e74d-4189-8d3f-827d071673ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.æå–æ•°ç‹¬ä¸­çš„æ•°å­—"
      ],
      "metadata": {
        "collapsed": false,
        "id": "FYMmP4XDMopq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done on 2023-04-27 03:29:24.696708\n"
          ]
        }
      ],
      "source": [
        "# Iterate over images in input folder\n",
        "fp = list(os.listdir(output_path))\n",
        "for file_name in fp:\n",
        "    if file_name.split('_')[0] != 'extract':\n",
        "        continue\n",
        "    # Load image\n",
        "    img = cv2.imread(os.path.join(output_path, file_name))\n",
        "    # Get dimensions of image\n",
        "    height, width, _ = img.shape\n",
        "    # Calculate size of each small image\n",
        "    size = int(height / 9)\n",
        "    # Iterate over rows and columns of small images\n",
        "    for row in range(9):\n",
        "        for col in range(9):\n",
        "            # Calculate coordinates of small image\n",
        "            x1 = col * size\n",
        "            y1 = row * size\n",
        "            x2 = x1 + size\n",
        "            y2 = y1 + size\n",
        "            # Crop small image from main image\n",
        "            small_img = img[y1:y2, x1:x2]\n",
        "            # Save small image to output folder\n",
        "            small_img_file_name = '{}_{}.png'.format(os.path.splitext(file_name)[0], row * 9 + col)\n",
        "            cv2.imwrite(os.path.join(output_path, small_img_file_name), small_img)\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "lcwxRyO3Mopr",
        "outputId": "e05dc1c8-278e-42cb-b6d3-729c87d39643",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.å•ä¸ªæ•°å­—å›¾ç‰‡é¢„å¤„ç†\n",
        "åœ¨è¯†åˆ«å•ä¸ªæ•°å­—ä¹‹å‰ï¼Œéœ€è¦å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†ã€‚\n",
        "å—é™äºè®­ç»ƒæ¨¡å‹ï¼Œè¿›è¡ŒäºŒå€¼åŒ–+å»é»‘çº¿çš„é¢„å¤„ç†å¯ä»¥å¤§å¹…åº¦æé«˜è¯†åˆ«å‡†ç¡®ç‡"
      ],
      "metadata": {
        "collapsed": false,
        "id": "FWCQKS4iMopr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done on 2023-04-27 03:29:28.393855\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "\n",
        "# è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸ºé»‘ç™½å›¾\n",
        "folder_path = 'sudoku_pic/extract'\n",
        "for filename in os.listdir(folder_path):\n",
        "    if len(filename.split('_')) != 3:\n",
        "        continue\n",
        "    img = Image.open(f\"{folder_path}/{filename}\").convert('L')\n",
        "    # è·å–å›¾ç‰‡çš„å®½åº¦å’Œé«˜åº¦\n",
        "    width, height = img.size\n",
        "    cl = []\n",
        "    # éå†æ¯ä¸€è¡Œï¼Œå¦‚æœæ•´è¡Œåƒç´ ç‚¹>=80%éƒ¨åˆ†ä¸æ˜¯ç™½è‰²ï¼Œåˆ™å°†è¯¥è¡Œåƒç´ ç‚¹å…¨éƒ¨è½¬æ¢ä¸ºç™½è‰²\n",
        "    for y in range(height):\n",
        "        pixels = [img.getpixel((x, y)) for x in range(width)]\n",
        "        white_pixels = sum(1 for pixel in pixels if pixel == 255)\n",
        "        if white_pixels < width*0.2:\n",
        "            for x in range(width):\n",
        "                cl.append((x, y))\n",
        "    # éå†æ¯ä¸€åˆ—ï¼Œå¦‚æœæ•´åˆ—åƒç´ ç‚¹>=80%éƒ¨åˆ†ä¸æ˜¯ç™½è‰²ï¼Œåˆ™å°†è¯¥åˆ—åƒç´ ç‚¹å…¨éƒ¨è½¬æ¢ä¸ºç™½è‰²\n",
        "    for x in range(width):\n",
        "        pixels = [img.getpixel((x, y)) for y in range(height)]\n",
        "        white_pixels = sum(1 for pixel in pixels if pixel == 255)\n",
        "        if white_pixels < height*0.2:\n",
        "            for y in range(height):\n",
        "                cl.append((x, y))\n",
        "    # å°†æ‰€æœ‰çš„ç™½è‰²åƒç´ ç‚¹è½¬æ¢ä¸ºé»‘è‰²\n",
        "    for x, y in cl:\n",
        "        img.putpixel((x, y), 255)\n",
        "    # åè½¬å›¾ç‰‡é¢œè‰²\n",
        "    img = ImageOps.invert(img)\n",
        "    img.save(f\"{folder_path}/ok/ok_{filename}\")\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "RdixvuIPMopr",
        "outputId": "92620078-f7e8-4c56-a00d-b56c047857e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.è¯†åˆ«æ•°å­—å¹¶è½¬åŒ–ä¸ºæ•°ç‹¬\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "oqzkxEAiMopr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7037095 parameters, 0 gradients\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 3 0 0 2 0 0 6]\n",
            " [0 0 0 0 1 8 0 3 0]\n",
            " [7 1 0 0 0 0 0 0 2]\n",
            " [0 0 0 0 0 0 7 0 0]\n",
            " [3 5 0 0 6 0 0 0 0]\n",
            " [0 0 6 4 0 3 0 1 0]\n",
            " [0 0 0 0 0 0 9 4 0]\n",
            " [0 0 5 9 0 0 0 0 0]\n",
            " [9 0 2 6 0 0 0 0 0]]\n",
            "Done on 2023-04-27 03:45:20.362784\n"
          ]
        }
      ],
      "source": [
        "from torchvision.transforms import ToTensor, Resize\n",
        "from pathlib import Path\n",
        "import sys\n",
        "from models.experimental import attempt_load\n",
        "from utils.general import non_max_suppression\n",
        "from utils.torch_utils import select_device\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "global sudoku_\n",
        "\n",
        "sys.path.insert(0, str(Path('yolov5')))\n",
        "\n",
        "def load_model(model_path):\n",
        "    device = select_device()\n",
        "    model = attempt_load(model_path, device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def predict(model, image_path):\n",
        "    device = select_device()\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img = Resize((128, 128))(img)\n",
        "    img_tensor = ToTensor()(img).unsqueeze(0).to(device)\n",
        "    pred = model(img_tensor)[0]\n",
        "    # Apply non-max suppression\n",
        "    results = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False)\n",
        "    return results, img.size\n",
        "\n",
        "def process_images(model_path, image_folder):\n",
        "    global sudoku_\n",
        "    model = load_model(model_path)\n",
        "    sudoku = np.zeros((9, 9), dtype=np.int32)\n",
        "    for img_name in sorted(os.listdir(image_folder)):\n",
        "        if img_name.startswith(\"ok_extract_\"):\n",
        "            row = int(img_name.split(\"_\")[3].split('.')[0]) // 9\n",
        "            col = int(img_name.split(\"_\")[3].split('.')[0]) % 9\n",
        "            img_path = os.path.join(image_folder, img_name)\n",
        "            results, img_size = predict(model, img_path)\n",
        "            if len(results) > 0 and len(results[0]) > 0:\n",
        "                most_likely_class = int(results[0][0][5].item())\n",
        "                sudoku[row, col] = most_likely_class\n",
        "        else:\n",
        "            continue\n",
        "    sudoku_=sudoku\n",
        "process_images(\"detect_number.pt\", \"sudoku_pic/extract/ok\")\n",
        "print(sudoku_)\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "YdfpptdjMopr",
        "outputId": "a8b7b9e8-cda2-4ce2-8e5f-593970ccef05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.æ±‚è§£æ•°ç‹¬\n"
      ],
      "metadata": {
        "id": "pZ_JEi2-q78q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "global sudoku_2\n",
        "def solve_sudoku_from_np_array(input_array):\n",
        "    global sudoku_2\n",
        "    input_array = input_array.copy() \n",
        "    def dfs(x, y):\n",
        "        if x == 9:\n",
        "            return True\n",
        "        if y == 9:\n",
        "            return dfs(x + 1, 0)\n",
        "        if input_array[x][y]:\n",
        "            return dfs(x, y + 1)\n",
        "        \n",
        "        id = xy_id[x][y]\n",
        "        for k in range(1, 10):\n",
        "            if hang[x][k] or lie[y][k] or kuai[id][k]:\n",
        "                continue\n",
        "            input_array[x][y] = k\n",
        "            hang[x][k] = 1\n",
        "            lie[y][k] = 1\n",
        "            kuai[id][k] = 1\n",
        "            \n",
        "            if dfs(x, y + 1):\n",
        "                return True\n",
        "            \n",
        "            input_array[x][y] = 0\n",
        "            hang[x][k] = 0\n",
        "            lie[y][k] = 0\n",
        "            kuai[id][k] = 0\n",
        "        \n",
        "        return False\n",
        "\n",
        "    hang = np.zeros((9, 10), dtype=int)\n",
        "    lie = np.zeros((9, 10), dtype=int)\n",
        "    kuai = np.zeros((9, 10), dtype=int)\n",
        "\n",
        "    xy_id = np.array([\n",
        "        [0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
        "        [0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
        "        [0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
        "        [3, 3, 3, 4, 4, 4, 5, 5, 5],\n",
        "        [3, 3, 3, 4, 4, 4, 5, 5, 5],\n",
        "        [3, 3, 3, 4, 4, 4, 5, 5, 5],\n",
        "        [6, 6, 6, 7, 7, 7, 8, 8, 8],\n",
        "        [6, 6, 6, 7, 7, 7, 8, 8, 8],\n",
        "        [6, 6, 6, 7, 7, 7, 8, 8, 8]\n",
        "    ])\n",
        "\n",
        "    for i in range(9):\n",
        "        for j in range(9):\n",
        "            if input_array[i][j] != 0:\n",
        "                num = input_array[i][j]\n",
        "                hang[i][num] = 1\n",
        "                lie[j][num] = 1\n",
        "                id = xy_id[i][j]\n",
        "                kuai[id][num] = 1\n",
        "\n",
        "    dfs(0, 0)\n",
        "\n",
        "    sudoku_2=input_array\n",
        "print(sudoku_)\n",
        "solve_sudoku_from_np_array(sudoku_)\n",
        "print(sudoku_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM07K3oJq-I8",
        "outputId": "ffdd438e-c141-4fdb-bf00-c1c0238b705c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 3 0 0 2 0 0 6]\n",
            " [0 0 0 0 1 8 0 3 0]\n",
            " [7 1 0 0 0 0 0 0 2]\n",
            " [0 0 0 0 0 0 7 0 0]\n",
            " [3 5 0 0 6 0 0 0 0]\n",
            " [0 0 6 4 0 3 0 1 0]\n",
            " [0 0 0 0 0 0 9 4 0]\n",
            " [0 0 5 9 0 0 0 0 0]\n",
            " [9 0 2 6 0 0 0 0 0]]\n",
            "[[5 8 3 7 4 2 1 9 6]\n",
            " [2 6 9 5 1 8 4 3 7]\n",
            " [7 1 4 3 9 6 8 5 2]\n",
            " [4 9 1 8 2 5 7 6 3]\n",
            " [3 5 7 1 6 9 2 8 4]\n",
            " [8 2 6 4 7 3 5 1 9]\n",
            " [6 3 8 2 5 7 9 4 1]\n",
            " [1 7 5 9 3 4 6 2 8]\n",
            " [9 4 2 6 8 1 3 7 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.å¡«å›åŸå›¾"
      ],
      "metadata": {
        "id": "fuH1RSUVxm28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def fill_sudoku_numbers(original_image_path, old_array, new_array):\n",
        "    old_array = np.array(old_array)\n",
        "    new_array = np.array(new_array)\n",
        "    print(old_array)\n",
        "    print(new_array)\n",
        "    # åŠ è½½åŸå§‹å›¾åƒ\n",
        "    original_image = cv2.imread(original_image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # è®¡ç®—æ¯ä¸ªå•å…ƒæ ¼çš„å¤§å°\n",
        "    cell_width = original_image.shape[1] // 9\n",
        "    cell_height = original_image.shape[0] // 9\n",
        "\n",
        "    # è®¾ç½®å­—ä½“\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = (cell_width + cell_height) / 100\n",
        "    font_thickness = int((cell_width + cell_height) / 25)\n",
        "\n",
        "    for i in range(9):\n",
        "        for j in range(9):\n",
        "            if old_array[i][j] == 0 and new_array[i][j] != 0:\n",
        "                # è®¡ç®—æ•°å­—åœ¨å›¾åƒä¸­çš„åæ ‡\n",
        "                x = cell_width * j + cell_width // 2\n",
        "                y = cell_height * i + cell_height // 2\n",
        "                print(x,y)\n",
        "                # åœ¨åŸå§‹å›¾åƒä¸Šå¡«å……æ•°å­—\n",
        "                cv2.putText(original_image, str(new_array[i][j]), (x, y), font, font_scale, (0, 0, 255), font_thickness, cv2.LINE_AA)\n",
        "\n",
        "    # ä¿å­˜å¡«å……åçš„å›¾åƒ\n",
        "    filled_image_path = \"/content/sudoku_pic/extract/filled_extract_1.png\"\n",
        "    cv2.imwrite(filled_image_path, original_image)\n",
        "\n",
        "    return filled_image_path\n",
        "\n",
        "original_image_path = \"/content/sudoku_pic/extract/extract_1.png\"\n",
        "fill_sudoku_numbers(original_image_path,sudoku_,sudoku_2)\n"
      ],
      "metadata": {
        "id": "XoK-Daiaxqwc",
        "outputId": "dc136dfa-f0c2-4b34-b239-7dd7a6e3396d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 3 0 0 2 0 0 6]\n",
            " [0 0 0 0 1 8 0 3 0]\n",
            " [7 1 0 0 0 0 0 0 2]\n",
            " [0 0 0 0 0 0 7 0 0]\n",
            " [3 5 0 0 6 0 0 0 0]\n",
            " [0 0 6 4 0 3 0 1 0]\n",
            " [0 0 0 0 0 0 9 4 0]\n",
            " [0 0 5 9 0 0 0 0 0]\n",
            " [9 0 2 6 0 0 0 0 0]]\n",
            "[[5 8 3 7 4 2 1 9 6]\n",
            " [2 6 9 5 1 8 4 3 7]\n",
            " [7 1 4 3 9 6 8 5 2]\n",
            " [4 9 1 8 2 5 7 6 3]\n",
            " [3 5 7 1 6 9 2 8 4]\n",
            " [8 2 6 4 7 3 5 1 9]\n",
            " [6 3 8 2 5 7 9 4 1]\n",
            " [1 7 5 9 3 4 6 2 8]\n",
            " [9 4 2 6 8 1 3 7 5]]\n",
            "45 45\n",
            "135 45\n",
            "315 45\n",
            "405 45\n",
            "585 45\n",
            "675 45\n",
            "45 136\n",
            "135 136\n",
            "225 136\n",
            "315 136\n",
            "585 136\n",
            "765 136\n",
            "225 227\n",
            "315 227\n",
            "405 227\n",
            "495 227\n",
            "585 227\n",
            "675 227\n",
            "45 318\n",
            "135 318\n",
            "225 318\n",
            "315 318\n",
            "405 318\n",
            "495 318\n",
            "675 318\n",
            "765 318\n",
            "225 409\n",
            "315 409\n",
            "495 409\n",
            "585 409\n",
            "675 409\n",
            "765 409\n",
            "45 500\n",
            "135 500\n",
            "405 500\n",
            "585 500\n",
            "765 500\n",
            "45 591\n",
            "135 591\n",
            "225 591\n",
            "315 591\n",
            "405 591\n",
            "495 591\n",
            "765 591\n",
            "45 682\n",
            "135 682\n",
            "405 682\n",
            "495 682\n",
            "585 682\n",
            "675 682\n",
            "765 682\n",
            "135 773\n",
            "405 773\n",
            "495 773\n",
            "585 773\n",
            "675 773\n",
            "765 773\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/sudoku_pic/extract/filled_extract_1.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}